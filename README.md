# Sign-Language-Recognition-System
Project that aims at bringing equality to our society by helping deaf and mute people to actually communicate with others.

## General info
A Sign Language Recognition system is designed and implemented to recognize 26 gestures by hand gesture recognition system for text generation. The signs are captured by using web cam. It is based on the distances between the various landmarks. The landmarks encompasses the 4 point of all the fingers and thumb. The distance calculated between these landmarks during the gesture helps us to identify the letter. Finally, recognized gesture is converted into text. This system provides an opportunity for a deaf-dumb people to communicate with non-
signing people without the need of an interpreter.

## Technologies and Tools
* Python
* NumPy
* OpenCV
* Time
* Math
* Mediapipe

## Pros of our project
* This project was mainly done with consideration of ease of use and affordability which was primarily our goal.
* We tried to make our software easy to use, accommodate as well as affordable.
* Instead of running huge calculations behind, training huge datasets, storing the results, we targeted to find the uniqueness of each gesture and match with the input gestures.
* This approach has not only made the program to run fast but we could also achieve the above-mentioned targets.

## Cons of existing projects
* A major portion of the projects of Gesture translations, focuses on machine learning, using CNN or many other methods.
* On further research it was noticed that it doesnâ€™t only takes a larger space to store and run but also has a relatively complex GUI and usages.
* Also, most of them could not be accommodated in low end devices.
